{
  "remoteClasses": [
    {
      "name": "PlayerEndpoint",
      "extends": "UriEndpoint",
      "doc": "Retrieves content from seekable sources in reliable\nmode (does not discard media information) and inject \nthem into :term:`KMS`. It\ncontains one :rom:cls:`MediaSource` for each media type detected.",
      "constructors": [
        {
          "doc": "Create a PlayerEndpoint",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "The :rom:cls:`MediaPipeline` this PlayerEndpoint belongs to.",
              "type": "MediaPipeline"
            },
            {
              "name": "uri",
              "doc": "URI that will be played",
              "type": "String"
            },
            {
              "name": "useEncodedMedia",
              "doc": "use encoded instead of raw media. If the parameter is false then the\nelement uses raw media. Changing this parameter can affect stability\nseverely, as lost key frames lost will not be regenerated. Changing the media type does not\naffect to the result except in the performance (just in the case where\noriginal media and target media are the same) and in the problem with the\nkey frames. We strongly recommended not to use this parameter because\ncorrect behaviour is not guarantied.",
              "type": "boolean",
              "optional": true,
              "defaultValue": false
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "play",
          "doc": "Starts to send data to the endpoint :rom:cls:`MediaSource`",
          "params": []
        }
      ],
      "events": [
        "EndOfStream"
      ]
    },
    {
      "name": "MediaObject",
      "doc": "Base for all objects that can be created in the media server.",
      "abstract": true,
      "methods": [
        {
          "name": "getMediaPipeline",
          "doc": "Returns the pipeline to which this MediaObject belong, or the pipeline itself if invoked over a :rom:cls:`MediaPipeline`",
          "params": [],
          "return": {
            "doc": "the MediaPipeline this MediaObject belongs to.\n\nIf called on a :rom:cls:`MediaPipeline` it will return ``this``.",
            "type": "MediaPipeline"
          }
        },
        {
          "name": "getParent",
          "doc": "Returns the parent of this media object. The type of the parent depends on the type of the element that this method is called upon:\n\nThe parent of a :rom:cls:`MediaPad` is its :rom:cls:`MediaElement`; the parent of a :rom:cls:`MediaMixer` or a :rom:cls:`MediaElement` is its :rom:cls:`MediaPipeline`.\n\nA :rom:cls:`MediaPipeline` has no parent, i.e. the method returns null",
          "params": [],
          "return": {
            "doc": "the parent of this MediaObject or null if called on a MediaPipeline",
            "type": "MediaObject"
          }
        }
      ],
      "events": [
        "Error"
      ]
    },
    {
      "name": "HttpGetEndpoint",
      "extends": "HttpEndpoint",
      "doc": "An ``HttpGetEndpoint`` contains SOURCE pads for AUDIO and VIDEO, delivering media using HTML5 pseudo-streaming mechanism.\n\n   This type of endpoint provide unidirectional communications. Its :rom:cls:`MediaSink` is associated with the HTTP GET method",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`HttpGetEndpoint`.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the endpoint belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "terminateOnEOS",
              "doc": "raise a :rom:evnt:`MediaSessionTerminated` event when the associated player raises a :rom:evnt:`EndOfStream`, and thus terminate the media session",
              "type": "boolean",
              "optional": true,
              "defaultValue": false
            },
            {
              "name": "mediaProfile",
              "doc": "the :rom:enum:`MediaProfileSpecType` (WEBM, MP4...) for the endpoint",
              "type": "MediaProfileSpecType",
              "optional": true,
              "defaultValue": "WEBM"
            },
            {
              "name": "disconnectionTimeout",
              "doc": "disconnection timeout in seconds.\n\nThis is the time that an http endpoint will wait for a reconnection, in case an HTTP connection is lost.",
              "type": "int",
              "optional": true,
              "defaultValue": 2
            }
          ]
        }
      ]
    },
    {
      "name": "WebRtcEndpoint",
      "extends": "SdpEndpoint",
      "doc": "WebRtcEndpoint interface. This type of ``Endpoint`` offers media streaming using WebRTC.",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`WebRtcEndpoint`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the endpoint belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ]
    },
    {
      "name": "SessionEndpoint",
      "doc": "Session based endpoint. A session is considered to be started when the media exchange starts. On the other hand, sessions terminate when a timeout, defined by the developer, takes place after the connection is lost.",
      "abstract": true,
      "extends": "Endpoint",
      "events": [
        "MediaSessionTerminated",
        "MediaSessionStarted"
      ]
    },
    {
      "name": "Hub",
      "extends": "MediaObject",
      "doc": "A Hub is a routing :rom:cls:`MediaObject`. It connects several :rom:cls:`endpoints <Endpoint>` together",
      "abstract": true
    },
    {
      "name": "ZBarFilter",
      "extends": "Filter",
      "doc": "This filter detects :term:`QR` codes in a video feed. When a code is found, the filter raises a :rom:evnt:`CodeFound` event.",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`ZBarFilter`.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ],
      "events": [
        "CodeFound"
      ]
    },
    {
      "name": "Filter",
      "abstract": true,
      "extends": "MediaElement",
      "doc": "Base interface for all filters. This is a certain type of :rom:cls:`MediaElement`, that processes media injected through its :rom:cls:`MediaSink`, and delivers the outcome through its :rom:cls:`MediaSource`."
    },
    {
      "name": "Endpoint",
      "abstract": true,
      "extends": "MediaElement",
      "doc": "Base interface for all end points. An Endpoint is a :rom:cls:`MediaElement`\nthat allow :term:`KMS` to interchange media contents with external systems,\nsupporting different transport protocols and mechanisms, such as :term:`RTP`,\n:term:`WebRTC`, :term:`HTTP`, ``file:/`` URLs... An ``Endpoint`` may\ncontain both sources and sinks for different media types, to provide\nbidirectional communication."
    },
    {
      "name": "HubPort",
      "extends": "MediaElement",
      "doc": "This :rom:cls:`MediaElement` specifies a connection with a :rom:cls:`Hub`",
      "constructors": [
        {
          "doc": "Creates a :rom:cls:`HubPort` for the given :rom:cls:`Hub`",
          "params": [
            {
              "name": "hub",
              "doc": ":rom:cls:`Hub` to which this port belongs",
              "type": "Hub"
            }
          ]
        }
      ]
    },
    {
      "name": "PointerDetectorAdvFilter",
      "extends": "Filter",
      "doc": "This type of :rom:cls:`Filter` detects UI pointers in a video feed.",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`PointerDetectorAdvFilter`.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "calibrationRegion",
              "doc": "region to calibrate the filter",
              "type": "WindowParam"
            },
            {
              "name": "windows",
              "doc": "list of detection windows for the filter.",
              "type": "PointerDetectorWindowMediaParam[]",
              "optional": true
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "addWindow",
          "doc": " Adds a new detection window for the filter to detect pointers entering or exiting the window",
          "params": [
            {
              "name": "window",
              "doc": "The window to be added",
              "type": "PointerDetectorWindowMediaParam"
            }
          ]
        },
        {
          "name": "clearWindows",
          "doc": "Removes all pointer detector windows",
          "params": []
        },
        {
          "name": "trackColorFromCalibrationRegion",
          "doc": "This method allows to calibrate the tracking color.\n\nThe new tracking color will be the color of the object in the colorCalibrationRegion.",
          "params": []
        },
        {
          "name": "removeWindow",
          "doc": "Removes a window from the list to be monitored",
          "params": [
            {
              "name": "windowId",
              "doc": "the id of the window to be removed",
              "type": "String"
            }
          ]
        }
      ],
      "events": [
        "WindowIn",
        "WindowOut"
      ]
    },
    {
      "name": "UriEndpoint",
      "abstract": true,
      "extends": "Endpoint",
      "doc": "Interface for endpoints the require a URI to work. An example of this, would be a :rom:cls:`PlayerEndpoint` whose URI property could be used to locate a file to stream through its :rom:cls:`MediaSource`",
      "methods": [
        {
          "name": "getUri",
          "doc": "Returns the uri for this endpoint.",
          "params": [],
          "return": {
            "doc": "the uri as a String",
            "type": "String"
          }
        },
        {
          "name": "pause",
          "doc": "Pauses the feed",
          "params": []
        },
        {
          "name": "stop",
          "doc": "Stops the feed",
          "params": []
        }
      ]
    },
    {
      "name": "HttpPostEndpoint",
      "extends": "HttpEndpoint",
      "doc": "An :rom:cls:`HttpPostEndpoint` contains SINK pads for AUDIO and VIDEO, which provide access to an HTTP file upload function\n\n   This type of endpoint provide unidirectional communications. Its :rom:cls:`MediaSources <MediaSource>` are accessed through the :term:`HTTP` POST method.",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`HttpPostEndpoint`.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the endpoint belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "disconnectionTimeout",
              "doc": "This is the time that an http endpoint will wait for a reconnection, in case an HTTP connection is lost.",
              "type": "int",
              "optional": true,
              "defaultValue": 2
            },
            {
              "name": "useEncodedMedia",
              "doc": "configures the endpoint to use encoded media instead of raw media. If the parameter is not set then the element uses raw media. Changing this parameter could affect in a severe way to stability because key frames lost will not be generated. Changing the media type does not affect to the result except in the performance (just in the case where original media and target media are the same) and in the problem with the key frames. We strongly recommended not to use this parameter because correct behaviour is not guarantied.",
              "type": "boolean",
              "optional": true,
              "defaultValue": false
            }
          ]
        }
      ],
      "events": [
        "EndOfStream"
      ]
    },
    {
      "name": "RtpEndpoint",
      "extends": "SdpEndpoint",
      "doc": "Endpoint that provides bidirectional content delivery capabilities with remote networked peers through RTP protocol. An :rom:cls:`RtpEndpoint` contains paired sink and source :rom:cls:`MediaPad` for audio and video.",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`RtpEndpoint`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the endpoint belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ]
    },
    {
      "name": "MediaPad",
      "abstract": true,
      "extends": "MediaObject",
      "doc": "A :rom:cls:`MediaPad` is an element´s interface with the outside world. The data streams flow from the :rom:cls:`MediaSource` pad to another element's :rom:cls:`MediaSink` pad.",
      "methods": [
        {
          "name": "getMediaElement",
          "doc": "Obtains the :rom:cls:`MediaElement` that encloses this pad",
          "params": [],
          "return": {
            "doc": "the element",
            "type": "MediaElement"
          }
        },
        {
          "name": "getMediaType",
          "doc": "Obtains the type of media that this pad accepts",
          "params": [],
          "return": {
            "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.DATA` or :rom:attr:`MediaType.VIDEO`",
            "type": "MediaType"
          }
        },
        {
          "name": "getMediaDescription",
          "doc": "Obtains the description for this pad.\n\n   This method does not make a request to the media server, and is included to keep the simmetry with the rest of methods from the API.",
          "params": [],
          "return": {
            "doc": "The description",
            "type": "String"
          }
        }
      ]
    },
    {
      "name": "PointerDetectorFilter",
      "extends": "Filter",
      "doc": "This type of :rom:cls:`Filter` detects pointers in a video feed.",
      "constructors": [
        {
          "doc": "Builder for the :rom:cls:`PointerDetectorFilter`.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "windows",
              "doc": "list of detection windows for the filter to detect pointers entering or exiting the window",
              "type": "PointerDetectorWindowMediaParam[]",
              "optional": true
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "addWindow",
          "doc": "Adds a pointer detector window. When a pointer enters or exits this window, the filter will raise an event indicating so.",
          "params": [
            {
              "name": "window",
            "doc": "the detection window",
              "type": "PointerDetectorWindowMediaParam"
            }
          ]
        },
        {
          "name": "clearWindows",
          "doc": "Removes all pointer detector windows",
          "params": []
        },
        {
          "name": "removeWindow",
          "doc": "Removes a pointer detector window",
          "params": [
            {
              "name": "windowId",
              "doc": "id of the window to be removed",
              "type": "String"
            }
          ]
        }
      ],
      "events": [
        "WindowIn",
        "WindowOut"
      ]
    },
    {
      "name": "MediaSource",
      "abstract": true,
      "extends": "MediaPad",
      "doc": "Special type of pad, used by a media element to generate a media stream.",
      "methods": [
        {
          "name": "getConnectedSinks",
          "doc": "Gets all the :rom:cls:`MediaSinks<MediaSink>` to which this source is connected",
          "params": [],
          "return": {
            "doc": "the list of sinks that the source is connected to",
            "type": "MediaSink[]"
          }
        },
        {
          "name": "connect",
          "doc": "Connects the current source with a :rom:cls:`MediaSink`",
          "params": [
            {
              "name": "sink",
              "doc": "The sink to connect this source",
              "type": "MediaSink"
            }
          ]
        }
      ]
    },
    {
      "name": "ChromaFilter",
      "extends": "Filter",
      "doc": "ChromaFilter interface. This type of :rom:cls:`Filter` makes transparent a colour\nrange in the top layer, revealing another image behind",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`ChromaFilter`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "window",
              "doc": "Window of replacement for the :rom:cls:`ChromaFilter`",
              "type": "WindowParam"
            },
            {
              "name": "backgroundImage",
              "doc": "url of image to be used to replace the detected background",
              "type": "String",
              "optional": true
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "setBackground",
          "doc": "Sets the image to show on the detected chroma surface.",
          "params": [
            {
              "name": "uri",
              "doc": "URI where the image is located",
              "type": "String"
            }
          ]
        },
        {
          "name": "unsetBackground",
          "doc": "Clears the image used to be shown behind the chroma surface.",
          "params": []
        }
      ]
    },
    {
      "name": "MediaPipeline",
      "extends": "MediaObject",
      "doc": "A pipeline is a container for a collection of :rom:cls:`MediaElements<MediaElement>` and :rom:cls:`MediaMixers<MediaMixer>`. It offers the methods needed to control the creation and connection of elements inside a certain pipeline.",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`MediaPipeline`",
          "params": [
          ]
        }
      ]
    },
    {
      "name": "MediaSink",
      "abstract": true,
      "extends": "MediaPad",
      "doc": "Special type of pad, used by a :rom:cls:`MediaElement` to receive a media stream.",
      "methods": [
        {
          "name": "disconnect",
          "doc": "Disconnects the current sink from the referred :rom:cls:`MediaSource`",
          "params": [
            {
              "name": "src",
              "doc": "The source to disconnect",
              "type": "MediaSource"
            }
          ]
        },
        {
          "name": "getConnectedSrc",
          "doc": "Gets the :rom:cls:`MediaSource` that is connected to this sink.",
          "params": [],
          "return": {
            "doc": "The source connected to this sink",
            "type": "MediaSource"
          }
        }
      ]
    },
    {
      "name": "Dispatcher",
      "doc": "A :rom:cls:`Hub` that allows routing between arbitrary port pairs",
      "extends": "Hub",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`Dispatcher` belonging to the given pipeline.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the dispatcher belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "connect",
          "doc": "Connects each corresponding :rom:enum:`MediaType` of the given source port with the sink port.",
          "params": [
            {
              "name": "source",
              "doc": "Source port to be connected",
              "type": "HubPort"
            },
            {
              "name": "sink",
              "doc": "Sink port to be connected",
              "type": "HubPort"
            }
          ]
        }
      ]
    },
    {
      "name": "DispatcherOneToMany",
      "extends": "Hub",
      "doc": "A :rom:cls:`Hub` that sends a given source to all the connected sinks",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`DispatcherOneToMany` belonging to the given pipeline.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the dispatcher belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "setSource",
          "doc": "Sets the source port that will be connected to the sinks of every :rom:cls:`HubPort` of the dispatcher",
          "params": [
            {
              "name": "source",
              "doc": "source to be broadcasted",
              "type": "HubPort"
            }
          ]
        },
        {
          "name": "removeSource",
          "doc": "Remove the source port and stop the media pipeline.",
          "params": []
        }
      ]
    },
    {
      "name": "Mixer",
      "doc": "A :rom:cls:`Hub` that allows routing of video between arbitrary port pairs and mixing of audio among several ports",
      "extends": "Hub",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`Mixer` belonging to the given pipeline.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the Mixer belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "connect",
          "doc": "Connects each corresponding :rom:enum:`MediaType` of the given source port with the sink port.",
          "params": [
            {
              "name": "media",
              "doc": "The sort of media stream to be connected",
              "type": "MediaType"
            },
            {
              "name": "source",
              "doc": "Video source port to be connected",
              "type": "HubPort"
            },
            {
              "name": "sink",
              "doc": "Video sink port to be connected",
              "type": "HubPort"
            }
          ]
        },
        {
          "name": "disconnect",
          "doc": "Disonnects each corresponding :rom:enum:`MediaType` of the given source port from the sink port.",
          "params": [
            {
              "name": "media",
              "doc": "The sort of media stream to be disconnected",
              "type": "MediaType"
            },
            {
              "name": "source",
              "doc": "Audio source port to be disconnected",
              "type": "HubPort"
            },
            {
              "name": "sink",
              "doc": "Audio sink port to be disconnected",
              "type": "HubPort"
            }
          ]
        }
      ]
    },
    {
      "name": "Composite",
      "extends": "Hub",
      "doc": "A :rom:cls:`Hub` that mixes the :rom:attr:`MediaType.AUDIO` stream of its connected sources and constructs a grid with the :rom:attr:`MediaType.VIDEO` streams of its connected sources into its sink",
      "constructors": [
        {
          "doc": "Create for the given pipeline",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the dispatcher belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ]
    },
    {
      "name": "JackVaderFilter",
      "extends": "Filter",
      "doc": "Filter that detects faces in a video feed. Those on the right half of the feed are overlaid with a pirate hat, and those on the left half are covered by a Darth Vader helmet. This is an example filter, intended to demonstrate how to integrate computer vision capabilities into the multimedia infrastructure.",
      "constructors": [
        {
          "doc": "Create a new :rom:cls:`Filter`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            }
          ]
        }
      ]
    },
    {
      "name": "HttpEndpoint",
      "abstract": true,
      "extends": "SessionEndpoint",
      "doc": "Endpoint that enables Kurento to work as an HTTP server, allowing peer HTTP clients to access media.",
      "methods": [
        {
          "name": "getUrl",
          "doc": "Obtains the URL associated to this endpoint",
          "params": [],
          "return": {
            "doc": "The url as a String",
            "type": "String"
          }
        }
      ]
    },
    {
      "name": "SdpEndpoint",
      "abstract": true,
      "extends": "SessionEndpoint",
      "doc": "Implements an SDP negotiation endpoint able to generate and process offers/responses and that configures resources according to negotiated Session Description",
      "methods": [
        {
          "name": "generateOffer",
          "doc": "Request a SessionSpec offer.\n\n   This can be used to initiate a connection.",
          "params": [],
          "return": {
            "doc": "The SDP offer.",
            "type": "String"
          }
        },
        {
          "name": "processOffer",
          "doc": "Request the NetworkConnection to process the given SessionSpec offer (from the remote User Agent)",
          "params": [
            {
              "name": "offer",
              "doc": "SessionSpec offer from the remote User Agent",
              "type": "String"
            }
          ],
          "return": {
            "doc": "The chosen configuration from the ones stated in the SDP offer",
            "type": "String"
          }
        },
        {
          "name": "processAnswer",
          "doc": "Request the NetworkConnection to process the given SessionSpec answer (from the remote User Agent).",
          "params": [
            {
              "name": "answer",
              "doc": "SessionSpec answer from the remote User Agent",
              "type": "String"
            }
          ],
          "return": {
            "doc": "Updated SDP offer, based on the answer received.",
            "type": "String"
          }
        },
        {
          "name": "getLocalSessionDescriptor",
          "doc": "This method gives access to the SessionSpec offered by this NetworkConnection.\n\n.. note:: This method returns the local MediaSpec, negotiated or not. If no offer has been generated yet, it returns null. It an offer has been generated it returns the offer and if an answer has been processed it returns the negotiated local SessionSpec.",
          "params": [],
          "return": {
            "doc": "The last agreed SessionSpec",
            "type": "String"
          }
        },
        {
          "name": "getRemoteSessionDescriptor",
          "doc": "This method gives access to the remote session description.\n\n.. note:: This method returns the media previously agreed after a complete offer-answer exchange. If no media has been agreed yet, it returns null.",
          "params": [],
          "return": {
            "doc": "The last agreed User Agent session description",
            "type": "String"
          }
        }
      ]
    },
    {
      "name": "FaceOverlayFilter",
      "extends": "Filter",
      "doc": "FaceOverlayFilter interface. This type of :rom:cls:`Filter` detects faces in a video feed. The face is then overlaid with an image.",
      "constructors": [
        {
          "doc": "FaceOverlayFilter interface. This type of :rom:cls:`Filter` detects faces in a video feed. The face is then overlaid with an image.",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "pipeline to which this :rom:cls:`Filter` belons",
              "type": "MediaPipeline"
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "unsetOverlayedImage",
          "doc": "Clear the image to be shown over each detected face. Stops overlaying the faces.",
          "params": []
        },
        {
          "name": "setOverlayedImage",
          "doc": "Sets the image to use as overlay on the detected faces.",
          "params": [
            {
              "name": "uri",
              "doc": "URI where the image is located",
              "type": "String"
            },
            {
              "name": "offsetXPercent",
              "doc": "the offset applied to the image, from the X coordinate of the detected face upper right corner. A positive value indicates right displacement, while a negative value moves the overlaid image to the left. This offset is specified as a percentage of the face width.\n\nFor example, to cover the detected face with the overlaid image, the parameter has to be ``0.0``. Values of ``1.0`` or ``-1.0`` indicate that the image upper right corner will be at the face´s X coord, +- the face´s width.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            },
            {
              "name": "offsetYPercent",
              "doc": "the offset applied to the image, from the Y coordinate of the detected face upper right corner. A positive value indicates up displacement, while a negative value moves the overlaid image down. This offset is specified as a percentage of the face width.\n\nFor example, to cover the detected face with the overlaid image, the parameter has to be ``0.0``. Values of ``1.0`` or ``-1.0`` indicate that the image upper right corner will be at the face´s Y coord, +- the face´s width.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            },
            {
              "name": "widthPercent",
              "doc": "proportional width of the overlaid image, relative to the width of the detected face. A value of 1.0 implies that the overlaid image will have the same width as the detected face. Values greater than 1.0 are allowed, while negative values are forbidden.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            },
            {
              "name": "heightPercent",
              "doc": "proportional height of the overlaid image, relative to the height of the detected face. A value of 1.0 implies that the overlaid image will have the same height as the detected face. Values greater than 1.0 are allowed, while negative values are forbidden.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            }
          ]
        }
      ]
    },
    {
      "name": "PlateDetectorFilter",
      "extends": "Filter",
      "doc": "PlateDetectorFilter interface. This type of :rom:cls:`Endpoint` detects\nvehicle plates in a video feed.",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`PlateDetectorFilter` for the given :rom:cls:`MediaPipeline`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the parent :rom:cls:`MediaPipeline` of this :rom:cls:`PlateDetectorFilter`",
              "type": "MediaPipeline"
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "setPlateWidthPercentage",
          "doc": "Configures the average width of the license plates in the image represented as an image percentage.",
          "params": [
            {
              "name": "plateWidthPercentage",
              "doc": "average width of the license plates represented as an image percentage [0..1].",
              "type": "float"
            }
          ]
        }
      ],
      "events": [
        "PlateDetected"
      ]
    },
    {
      "name": "RecorderEndpoint",
      "extends": "UriEndpoint",
      "doc": "Provides function to store contents in reliable mode (doesn't discard data). It contains :rom:cls:`MediaSink` pads for audio and video.",
      "constructors": [
        {
          "doc": "",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the endpoint belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "uri",
              "doc": "URI where the recording will be stored",
              "type": "String"
            },
            {
              "name": "mediaProfile",
              "doc": "Choose either a :rom:attr:`MediaProfileSpecType.WEBM` or a :rom:attr:`MediaProfileSpecType.MP4` profile for recording",
              "type": "MediaProfileSpecType",
              "optional": true,
              "defaultValue": "WEBM"
            },
            {
              "name": "stopOnEndOfStream",
              "doc": "Forces the recorder endpoint to finish processing data when an :term:`EOS` is detected in the stream",
              "type": "boolean",
              "optional": true,
              "defaultValue": false
            }
          ]
        }
      ],
      "methods": [
        {
          "name": "record",
          "doc": "Starts storing media received through the :rom:cls:`MediaSink` pad",
          "params": []
        }
      ]
    },
    {
      "name": "MediaElement",
      "abstract": true,
      "extends": "MediaObject",
      "doc": "Basic building blocks of the media server, that can be interconnected through the API. A :rom:cls:`MediaElement` is a module that encapsulates a specific media capability. They can be connected to create media pipelines where those capabilities are applied, in sequence, to the stream going through the pipeline.\n\n   :rom:cls:`MediaElement` objects are classified by its supported media type (audio, video, etc.) and the flow direction: :rom:cls:`MediaSource` pads are intended for media delivery while :rom:cls:`MediaSinks<MediaSink>`  behave as reception points.",
      "methods": [
        {
          "name": "getMediaSrcs",
          "doc": "Get the :rom:cls:`sources <MediaSource>` of this element",
          "params": [],
          "return": {
            "doc": "A list of sources. The list will be empty if no sources are found.",
            "type": "MediaSource[]"
          }
        },
        {
          "name": "getMediaSrcs",
          "doc": "Get the media sources of the given type and description",
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType"
            },
            {
              "name": "description",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String"
            }
          ],
          "return": {
            "doc": "A list of sources. The list will be empty if no sources are found.",
            "type": "MediaSource[]"
          }
        },
        {
          "name": "getMediaSrcs",
          "doc": "get media sources of the given type",
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType"
            }
          ],
          "return": {
            "doc": "A list of sources. The list will be empty if no sources are found.",
            "type": "MediaSource[]"
          }
        },
        {
          "name": "getMediaSinks",
          "doc": "Get the :rom:cls:`sinks <MediaSink>` of this element",
          "params": [],
          "return": {
            "doc": "A list of sinks. The list will be empty if no sinks are found.",
            "type": "MediaSink[]"
          }
        },
        {
          "name": "getMediaSinks",
          "doc": "A list of sinks of the given :rom:ref:`MediaType`. The list will be empty if no sinks are found.",
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType"
            }
          ],
          "return": {
            "doc": "A list of sinks. The list will be empty if no sinks are found.",
            "type": "MediaSink[]"
          }
        },
        {
          "name": "getMediaSinks",
          "doc": "A list of sinks of the given :rom:ref:`MediaType`. The list will be empty if no sinks are found.",
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType"
            },
            {
              "name": "description",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String"
            }
          ],
          "return": {
            "doc": "A list of sinks. The list will be empty if no sinks are found.",
            "type": "MediaSink[]"
          }
        },
        {
          "name": "connect",
          "doc": "perform :rom:meth:`connect(sink,mediaType)` if there is exactly one sink for the given type, and their mediaDescriptions are the same",
          "params": [
            {
              "name": "sink",
              "doc": "the target :rom:cls:`MediaElement`  from which :rom:cls:`MediaSink` will be obtained",
              "type": "MediaElement"
            },
            {
              "name": "mediaType",
              "doc": "the :rom:enum:`MediaType` of the pads that will be connected",
              "type": "MediaType"
            },
            {
              "name": "mediaDescription",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String"
            }
          ]
        },
        {
          "name": "connect",
          "doc": "Connects every :rom:cls:`MediaSource` of this element belonging to the specified :rom:enum:`MediaType` to the corresponding :rom:cls:`MediaSink` of the target :rom:cls:`MediaElement`. This method will throw an exception if any of the following occur:\n\n   ..\n\n   * The number of sources for the specified :rom:enum:`MediaType` in this element is different than the number of sinks on the target element.\n   * There are duplicate mediaDescriptions on this' element sources for the specified :rom:enum:`MediaType`.\n   * There are duplicate mediaDescriptions on target's element sinks for the specified :rom:enum:`MediaType`.\n   * Target sinks' media descriptions are different form this sources' media descriptions for the specified :rom:enum:`MediaType`\n\nThis method is not transactional. In case of exception some of this element sources may be connected with target sinks.",
          "params": [
            {
              "name": "sink",
              "doc": "the target :rom:cls:`MediaElement`  from which :rom:cls:`MediaSink` will be obtained",
              "type": "MediaElement"
            },
            {
              "name": "mediaType",
              "doc": "the :rom:enum:`MediaType` of the pads that will be connected",
              "type": "MediaType"
            }
          ]
        },
        {
          "name": "connect",
          "doc": "perform :rom:meth:`connect(sink,mediaType)` for every available :rom:cls:`MediaType` in this source",
          "params": [
            {
              "name": "sink",
              "doc": "the target :rom:cls:`MediaElement`  from which :rom:cls:`MediaSink` will be obtained",
              "type": "MediaElement"
            }
          ]
        }
      ]
    },
    {
      "name": "GStreamerFilter",
      "extends": "Filter",
      "doc": "This is a generic filter interface, that creates GStreamer filters in the media server.",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`GStreamerFilter`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "command",
              "doc": "command that would be used to instantiate the filter, as in `gst-launch <http://rpm.pbone.net/index.php3/stat/45/idpl/19531544/numer/1/nazwa/gst-launch-1.0>`__",
              "type": "String"
            }
          ]
        }
      ]
    },
    {
      "name": "CrowdDetectorFilter",
      "doc": "Filter that detects people agglomeration in video streams",
      "extends": "Filter",
      "constructors": [
        {
          "doc": "Create a :rom:cls:`CrowdDetectorFilter`",
          "params": [
            {
              "name": "mediaPipeline",
              "doc": "the :rom:cls:`MediaPipeline` to which the filter belongs",
              "type": "MediaPipeline"
            },
            {
              "name": "rois",
              "doc": "Regions of interest for the filter",
              "type": "RegionOfInterest[]"
            }
          ]
        }
      ],
      "events": [
        "CrowdDetectorFluidity",
        "CrowdDetectorOccupancy",
        "CrowdDetectorDirection"
      ]
    }
  ],
  "complexTypes": [
    {
      "typeFormat": "ENUM",
      "values": [
        "WEBM",
        "MP4"
      ],
      "name": "MediaProfileSpecType",
      "doc": "Media Profile.\n\nCurrently WEBM and MP4 are supported."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "AUDIO",
        "DATA",
        "VIDEO"
      ],
      "name": "MediaType",
      "doc": "Type of media stream to be exchanged.\nCan take the values AUDIO, DATA or VIDEO."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "id",
          "doc": "id of the window for pointer detection",
          "type": "String"
        },
        {
          "name": "height",
          "doc": "height in pixels",
          "type": "int"
        },
        {
          "name": "width",
          "doc": "width in pixels",
          "type": "int"
        },
        {
          "name": "upperRightX",
          "doc": "X coordinate in pixels of the upper left corner",
          "type": "int"
        },
        {
          "name": "upperRightY",
          "doc": "Y coordinate in pixels of the upper left corner",
          "type": "int"
        },
        {
          "name": "activeImage",
          "doc": "uri of the image to be used when the pointer is inside the window",
          "type": "String",
          "optional": true
        },
        {
          "name": "imageTransparency",
          "doc": "transparency ratio of the image",
          "type": "float",
          "optional": true
        },
        {
          "name": "image",
          "doc": "uri of the image to be used for the window.\n\nIf :rom:attr:`activeImage` has been set, it will only be shown when the pointer is outside of the window.",
          "type": "String",
          "optional": true
        }
      ],
      "name": "PointerDetectorWindowMediaParam",
      "doc": "Data structure for UI Pointer detection in video streams.\n\nAll the coordinates are in pixels. X is horizontal, Y is vertical, running from the top of the window. Thus, 0,0 corresponds to the topleft corner."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "topRightCornerX",
          "doc": "X coordinate of the left upper point of the window",
          "type": "int"
        },
        {
          "name": "topRightCornerY",
          "doc": "Y coordinate of the left upper point of the window",
          "type": "int"
        },
        {
          "name": "width",
          "doc": "width in pixels of the window",
          "type": "int"
        },
        {
          "name": "height",
          "doc": "height in pixels of the window",
          "type": "int"
        }
      ],
      "name": "WindowParam",
      "doc": "Parameter representing a window in a video stream.\nIt is used in command and constructors for media elements.\n\nAll units are in pixels, X runs from left to right, Y from top to bottom."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "occupancyLevelMin",
          "doc": "minimun occupancy percentage in the ROI to send occupancy events",
          "type": "int",
          "optional": true,
          "defaultValue": 10
        },
        {
          "name": "occupancyLevelMed",
          "doc": "send occupancy level = 1 if the occupancy percentage is between occupancy_level_min and this level",
          "type": "int",
          "optional": true,
          "defaultValue": 35
        },
        {
          "name": "occupancyLevelMax",
          "doc": "send occupancy level = 2 if the occupancy percentage is between occupancy_level_med and this level,\nand send occupancy level = 3 if the occupancy percentage is between this level and 100",
          "type": "int",
          "optional": true,
          "defaultValue": 65
        },
        {
          "name": "occupancyNumFramesToEvent",
          "doc": "number of consecutive frames that a new occupancy level has to be detected to recognize it as a occupancy level change.\nA new occupancy event will be send",
          "type": "int",
          "optional": true,
          "defaultValue": 5
        },
        {
          "name": "fluidityLevelMin",
          "doc": "minimun fluidity percentage in the ROI to send fluidity events",
          "type": "int",
          "optional": true,
          "defaultValue": 10
        },
        {
          "name": "fluidityLevelMed",
          "doc": "send fluidity level = 1 if the fluidity percentage is between fluidity_level_min and this level",
          "type": "int",
          "optional": true,
          "defaultValue": 35
        },
        {
          "name": "fluidityLevelMax",
          "doc": "send fluidity level = 2 if the fluidity percentage is between fluidity_level_med and this level,\n and send fluidity level = 3 if the fluidity percentage is between this level and 100",
          "type": "int",
          "optional": true,
          "defaultValue": 65
        },
        {
          "name": "fluidityNumFramesToEvent",
          "doc": "number of consecutive frames that a new fluidity level has to be detected to recognize it as a fluidity level change.\n A new fluidity event will be send",
          "type": "int",
          "optional": true,
          "defaultValue": 5
        },
        {
          "name": "sendOpticalFlowEvent",
          "doc": "Enable/disable the movement direction detection into the ROI",
          "type": "boolean",
          "optional": true,
          "defaultValue": false
        },
        {
          "name": "opticalFlowNumFramesToEvent",
          "doc": "number of consecutive frames that a new direction of movement has to be detected to recognize a new movement direction. \n A new direction event will be send",
          "type": "int",
          "optional": true,
          "defaultValue": 3
        },
        {
          "name": "opticalFlowNumFramesToReset",
          "doc": "number of consecutive frames in order to reset the counter of repeated directions",
          "type": "int",
          "optional": true,
          "defaultValue": 3
        },
        {
          "name": "opticalFlowAngleOffset",
          "doc": "Direction of the movement. The angle could have four different values: \n left (0), up (90), right (180) and down (270). This cartesian axis could be rotated adding an angle offset",
          "type": "int",
          "optional": true,
          "defaultValue": 0
        }
      ],
      "name": "RegionOfInterestConfig",
      "doc": "data structure for configuration of CrowdDetector regions of interest"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "points",
          "doc": "list of points delimiting the region of interest",
          "type": "RelativePoint[]"
        },
        {
          "name": "regionOfInterestConfig",
          "doc": "data structure for configuration of CrowdDetector regions of interest",
          "type": "RegionOfInterestConfig"
        },
        {
          "name": "id",
          "doc": "identifier of the region of interest. The string used for the id must begin \n with a letter followed by an alphanumeric character included (/-_.:+)",
          "type": "String"
        }
      ],
      "name": "RegionOfInterest",
      "doc": "Region of interest for some events in a video processing filter"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "x",
          "doc": "X coordinate in pixels of a point in the screen",
          "type": "int"
        },
        {
          "name": "y",
          "doc": "Y coordinate in pixels of a point in the screen",
          "type": "int"
        }
      ],
      "name": "Point",
      "doc": "Point in a physical screen, coordinates are in pixels with X left to right and Y top to down."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "x",
          "doc": "Percentage relative to the image width to calculate the X coordinate of the point [0..1]",
          "type": "float"
        },
        {
          "name": "y",
          "doc": "Percentage relative to the image height to calculate the Y coordinate of the point [0..1]",
          "type": "float"
        }
      ],
      "name": "RelativePoint",
      "doc": "Relative points in a physical screen, values are a percentage relative to the image dimensions. X left to right and Y top to down."
    }
  ],
  "events": [
    {
      "properties": [
        {
          "name": "plate",
          "doc": "Plate identification that was detected by the filter",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "PlateDetected",
      "doc": "Event raised by a :rom:cls:`PlateDetectorFilter` when a plate is found in the data streamed."
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "EndOfStream",
      "doc": "Event raised when the stream that the element sends out is finished.\nAn element receiving this event will generally just process any buffered\ndata, and then forward the event further downstream."
    },
    {
      "properties": [
        {
          "name": "codeType",
          "doc": "type of :term:`QR` code found",
          "type": "String"
        },
        {
          "name": "value",
          "doc": "value contained in the :term:`QR` code",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CodeFound",
      "doc": "Event raised by a :rom:cls:`ZBarFilter` when a code is found in the data being streamed."
    },
    {
      "properties": [
        {
          "name": "object",
          "doc": ":rom:cls:`MediaObject` where the error originated",
          "type": "MediaObject"
        },
        {
          "name": "description",
          "doc": "Textual description of the error",
          "type": "String"
        },
        {
          "name": "errorCode",
          "doc": "Server side integer error code",
          "type": "int"
        },
        {
          "name": "type",
          "doc": "Integer code as a String",
          "type": "String"
        }
      ],
      "name": "Error",
      "doc": "An error related to the MediaObject has occurred"
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "MediaSessionTerminated",
      "doc": "Event raised when a session is terminated. This event has no data."
    },
    {
      "properties": [
        {
          "name": "windowId",
          "doc": "Opaque String indicating the id of the window entered",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "WindowIn",
      "doc": "Event generated when an object enters a window."
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "MediaSessionStarted",
      "doc": "Event raised when a session starts. This event has no data."
    },
    {
      "properties": [
        {
          "name": "windowId",
          "doc": "Opaque String indicating the id of the window entered",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "WindowOut",
      "doc": "Event generated when an object exits a window."

    },
    {
      "properties": [
        {
          "name": "source",
          "doc": "Object that raised the event",
          "type": "MediaObject"
        },
        {
          "name": "type",
          "doc": "Type of event that was raised",
          "type": "String"
        }
      ],
      "name": "Media",
      "doc": "Base for all events raised by elements in the Kurento media server."
    },
    {
      "properties": [
        {
          "name": "fluidityPercentage",
          "doc": "Percentage of fluidity in the ROI",
          "type": "float"
        },
        {
          "name": "fluidityLevel",
          "doc": "Level of fluidity in the ROI",
          "type": "int"
        },
        {
          "name": "roiID",
          "doc": "Opaque String indicating the id of the involved ROI",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CrowdDetectorFluidity",
      "doc": "Event raise when a level of fluidity is detected in a ROI"
    },
    {
      "properties": [
        {
          "name": "occupancyPercentage",
          "doc": "Percentage of occupancy in the ROI",
          "type": "float"
        },
        {
          "name": "occupancyLevel",
          "doc": "Level of occupancy in the ROI",
          "type": "int"
        },
        {
          "name": "roiID",
          "doc": "Opaque String indicating the id of the involved ROI",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CrowdDetectorOccupancy",
      "doc": "Event raise when a level of occupancy is detected in a ROI"
    },
    {
      "properties": [
        {
          "name": "directionAngle",
          "doc": "Direction angle of the detected movement in the ROI",
          "type": "float"
        },
        {
          "name": "roiID",
          "doc": "Opaque String indicating the id of the involved ROI",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CrowdDetectorDirection",
      "doc": "Event raise when a movement direction is detected in a ROI"
    }
  ]
}
